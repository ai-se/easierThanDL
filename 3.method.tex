\section{Method}

\subsection{Reserach problem}
To investigate {\it how deep learning techniques perform on software analytics compared 
with tuning baseline method}, we pick Xu et al.~\cite{xu2016predicting} work as a case study
where convolutional neural network(CNN), a deep learning technique, was proposed to 
solve a multi-class classification problem based on text data from Stack Overflow.

In that work, Xu et al. predict whether two questions posted on Stack Overflow are semantically linkable. 
Specifically,  a question along with its entire set of answers posted in Stack Overflow
as a {\it knowledge unit}. If two knowledge units are semantically related, they're considered
as {\it linkable} knowledge units. To predict relationships between two questions more precisely, 
Xu et al. further divide linkable  units 
into {\it duplicate}, {\it direct link}, {\it indirect link} and {\it isolated}  four different categories 
based on its relatedness. The details are listed as follows~\cite{xu2016predicting}:

\begin{itemize}
\item Duplicate:  these two knowledge units are addressing the same question.
\item Direct link: one knowledge unit can help to answer the question in the other knowledge unit.
\item Indirect link: one knowledge provide similar information to solve the question in the other knowledge unit, but not a direct answer.
\item Isolated: these two knowledge units discuss unrelated questions.
\end{itemize}

In that paper, Xu et al. provided the following two methods as baselines:

\begin{itemize}
\item TF-IDF + SVM: a multi-class SVM classifier with  36 textual features generated  based on the 
TF and IDF values of the words in a pair of knowledge units. 
\item Word Embedding + SVM:  a multi-class SVM classifier with word embedding generate by word2vec model~\cite{mikolov2013distributed}.
\end{itemize}
Both of these two baseline methods are compared against the proposed method, word embedding + CNN. 

Our concern is whether parameter tuning could help improve baseline method performance.
In this work, to fairly compare deep learning method to baseline methods with the parameter tuning,
we choose word embedding + SVM as our research subject since it uses the word embedding as the
input data, which is the same as CNN method. 
Instead of setting SVM parameters to constant values, we apply DE as a parameter tuner to find optimal tunings
for SVM. Then we compare the performance score of tuned SVM  with the CNN scores reported by Xu et al. 

%%%%%%%%%%%%%%%% list of parameters%%%%%%%%%%%%%%%%%%%%%
%\renewcommand\arraystretch{1.2}
\begin{table*}[t!]
%\scriptsize
 \small
  \centering
	\begin{tabular}{|c|c|c|c|l|}
	\cline{1-5}
	Parameters & Default &Xue et al.&Tuning Range& 
\multicolumn{1}{c|}{Description} \\ \hline
	C & 1.0 &unkown&[1, 50]& Penalty parameter C of the error term.\\ \cline{1-5} 
	 kernel & `rbf' &`rbf'&[`liner',`poly',`rbf',`sigmoid']& Specify the kernel type to be used in the algorithms. \\ \cline{1-5} 
	 gamma & {1/n\_features} &$1/200$& [0, 1]& Kernel coefficient for `rbf', `poly' and `sigmoid'. \\ \cline{1-5} 
	 coef0 & 0 & unkown & [0, 1] &  Independent term in kernel function. It is only used in `poly' and `sigmoid'. \\ \cline{1-5}
\hline
	\end{tabular}
    \caption {List of parameters tuned by this paper.}
\label{tab:parameters}
\end{table*}

\subsection{Learners and their parameters}
SVM has been proven to be a very successful method to solve
text classification problem. It seeks to minimize misclassification
errors by selecting a boundary or hyperplane that leaves
the maximum margin between positive and negative classes, where the
margin is defined as the sum of the distances of the
hyperplane from the closest point of the two classes\cite{joachims1998text}.

Like most machine learning algorithms, there're some parameters associated with
SMV to control how it learns.  In Xu et al.'s experiment, they used RBF for SVM kernel
and set $\gamma$ to $1/k$, where $k$ is $36$ for TF-IDF + SVM method
and $200$ for Word Embedding + SVM method. For other parameters, 
Xu et al. mentioned that grid search was applied to optimize the SVM parameters, 
but no further information disclose. 

In this work, we use the SVM module from Scikit-learn~\cite{scikit-learn}, a python package for machine learning,
where the following parameters shown in Table. ~\ref{tab:parameters} are selected for tuning.
Parameter {\it C} is to set the amount of regularization, which controls the tradeoff between
the errors on training data and the model complexity.  A small value for {\it C} will generate 
a simple model with more training errors, while a large value will lead to a complicated model with fewer
errors. {\it Kernel} is to introduce different nonlinearities into the SVM model by applying kernel functions
on the input data. {\it Gamma } defines how far the influence of a single training example reaches, 
with low values meaning `far' and high values meaning `close'. {\it coef0} is an independent parameter used
in sigmod and  polynomial kernel function.

As to why we used the ``Tuning Range'' shown in {parameters}, and not some other ranges,
we note that (1)~those ranges included the defaults and also Xu et al.'s values ; (2)~the results shown below
show that by exploring those ranges,   we achieved large gains in the performance of our defect predictors.
This is not to say that {\em larger} tuning ranges might not result in {\em greater} improvements.
However, for the goals of this paper (to show that some tunings do matter), exploring
just these ranges shown in \tab{parameters} will suffice.


%In this work, we investigate whether parameter tunings can improve the baseline method based on Xu et al. work.
%Specifically, to compare with the proposed method Word Embedding + CNN, we choose Word Embedding + SVM
%as our baseline, where both CNN and SVM methods are supplied with the same word embedding feature data. 


\subsection{learning Word Embedding}
Learning word embeddings refers to finding vector representations
of words such that the similarities between words can be captured by cosine similarity of corresponding 
vector representations. It's been shown that the words with similar semantic and syntactic are found closed
to each other in the embedding space~\cite{mikolov2013distributed}.

Several methods have been proposed to generate word embeddings, 
like skip-gram~\cite{mikolov2013distributed}, GloVe ~\cite{pennington2014glove}
and PCA on the word co-occurrence matrix~\cite{lebret2013word}. To replicate Xu et al. work,
we used continuous skip-gram model(word2vec),  which is a unsupervised word representation learning method based on
neural networks. 

The skip-gram model learns vector representations of words
 by predicting the surrounding words in a context window. 
 Given a sentence of words $W =w_1$,$w_2$,...,$w_n$, the objective of skip-gram model is to maximize the
 the average log probability of the surrounding words:
 \begin{equation*}
 \frac{1}{n}\sum_{i=1}^{n} \sum_{-c\leq j \leq c, j \neq 0} log p(w_{i+j}|w_i)
\end{equation*}
where $c$ is the context window size and $w_{t+j}$ and $w_{t}$ represent surrounding words and center word, respectively.
The probability of $p(w_{i+j}|w_i)$ is computed according to the softmax function:

\begin{equation*}
p(w_O|w_I) = \frac{exp(v_{w_O}^Tv_{w_I})}{\sum_{w=1}^{|W|}exp(v_{w}^Tv_{w_I})}
\end{equation*}
where $v_{w_I}$ and $v_{w_O}$ are the vector representations of the input and output vectors of $w$, respectively. 
$\sum_{w=1}^{|W|}exp(v_{w}^Tv_{w_I})$  normalizes the inner product results across all the words.
To improve the computation efficiency, Mikolove et al. \cite{mikolov2013distributed} proposed
hierachical softmax and negative sampling
techniques. More details can be found in ~\cite{mikolov2013distributed}.

As noted, skip-gram itself has several parameters that will drive the algorithm 
to learn the word embeddings,  like {\it window size} and {\it dimensionality of embedding space}. 
Zucoon et al. \cite{zuccon2015integrating} found that embedding dimensionality
and context window size have no consistent impact on retrieval model performance. However,
Yang et al.~\cite{yang2016using} showed that large context window and dimension
 sizes are preferable to improve the performance when using CNN to solve  classification tasks
 for Twitter. Since this work is to compare performance of  tuning SVM  with CNNs, where
 skip-gram model is used to generate word vector representations for both of thesemethods, 
 tuning parameter of skip-gram model is beyond the scope of this paper and we will leave it to feature work.
 
 

To train our word2vec model, $100,000$ knowledge units tagged with ``java'' from
Stack Overflow {\it posts} table  (include titles, questions and answers)
are randomly selected as a word corpus\footnote{Without further explanation, 
all the experiment settings, including learner algorithms,
training/testing data split, etc, strictly follow Xu et al.'s work. }. 
After applying proper data processing techniques proposed by Xu et al., like
 remove the unnecessary HTML tags and keep short code snippets in
{\it code} tag, then fit the corpus into {\it gensim} word2vec module ~\cite{rehurek_lrec},
which is a python wrapper over original word2vec package.

When converting knowledge units into vector representations, 
for each word $w_i$ in the post processed knowledge unit(including title, question and answers),
we query the trained skip-gram model to get the corresponding word vector representation $v_i$.
Then the whole knowledge unit with $s$ words
will be converted to vector representation by element-wise addition, $Uv = v_i \oplus v_2 \oplus...\oplus v_s $. 
This vector representation will be used
as the input data to SVM.




\subsection{Tuning Algorithm}

Tuning algorithm is an optimizer that will drive the learner to explore
the optimal parameter in a given searching space. According to our
literature review, there are several searching algorithms used in 
SE community:{\em 
simulated annealing}~\cite{feather2002converging,menzies2007data};
 various {\em genetic algorithms}~\cite{jones1996automatic,harman2007current, arcuri2011parameter} augmented by
techniques such as {\em differential evolution}
~\cite{storn1997differential, fu2016tuning, fu2016differential,chaves2015differential,agrawal2016wrong}, 
{\em tabu search} and {\em scatter search}~\cite{beausoleil2006moss,molina2007sspmo,corazza2013using};
{\em particle swarm optimization}~\cite{windisch2007applying}; 
numerous {\em decomposition} approaches that use
    heuristics to decompose the total space into   small problems,   then apply a
    {\em response surface methods}~\cite{krall2015gale};
     {\em NSGA II} ~\cite{zhang2007multi}and {\em NSGA III}~\cite{mkaouer2014high}.


Of all the mentioned algorithms,  the simplest are simulated annealing (SA)  and 
differential evolution (DE), each of which can be coded in less than a page of some high-level scripting language.
 Our reading of the current literature is that there are more  advocates for
differential evolution than SA. For example,  Vesterstrom and Thomsen~\cite{Vesterstrom04} found DE to be competitive with 
 particle swarm optimization and other GAs.  DEs have already been applied before for 
 parameter tuning (e.g. see~\cite{omran2005differential, chiha2012tuning, fu2016tuning, fu2016differential, agrawal2016wrong}) .
Therefore, in this work, we adopt DE as our tuning algorithm and 
the pseudocode for DE is shown in Algorithm~\ref{alg:DE}.
To better explain how DE work, in the following description, 
line number in the pseudocode is denoted as superscript numbers.

\begin{algorithm}[!t]

\scriptsize
\begin{algorithmic}[1]
\Require $\mathit{np} = 10$, $f=0.75$, $cr=0.3$, $\mathit{life} = 5$, $\mathit{Goal} \in \{\mathit{pd},f,...\}$
\Ensure $S_{best}$
\vspace{2mm}
\Function{DE}{$\mathit{np}$, $f$, $cr$, $\mathit{life}$, $\mathit{Goal}$}
 \State $Population  \gets $ InitializePopulation($\mathit{np}$)   
 \State $S_{best} \gets $GetBestSolution($Population $)
 \While{$\mathit{life} > 0$}
\State $NewGeneration \gets \emptyset$
\For{$i=0 \to \mathit{np}-1$}
\State $S_i \gets$ Extrapolate($Population [i], Population , cr, f$)
\If {Score($S_i$) >Score($Population [i]$)}
\State $NewGeneration$.append($S_i$)
\Else
\State $NewGeneration$.append($Population [i]$)
\EndIf
\EndFor
\State $Population  \gets NewGeneration$
\If{$\neg$ Improve($Population $)}
\State $life -=1$
\EndIf
\State $S_{best} \gets$ GetBestSolution($Population $)
 \EndWhile
\State \Return $S_{best}$
\EndFunction
\Function{Score}{$Candidate$}
   \State set tuned parameters according to $Candidate$
   \State $model \gets$TrainLearner()
   \State $result \gets$TestLearner($model$)   
   \State \Return$\mathit{Goal}(result)$  
\EndFunction
\Function{Extrapolate}{$old, pop, cr, f$}
  \State $a, b, c\gets threeOthers(pop,old)$  
  \State $newf \gets \emptyset$
  \For{$i=0 \to \mathit{np}-1$}
       \If{$cr < random()$}
         \State $newf$.append($old[i]$)
                \Else
                  \If{typeof($old[i]$) == bool}
                    \State $newf$.append(not $old[i]$)
         \Else
          \State $newf$.append(trim($i$,($a[i] + f * (b[i] - c[i]$)))) 
         \EndIf
       \EndIf
  \EndFor
 \State \Return $newf$
\EndFunction
        \end{algorithmic} 
\caption{Pseudocode for DE with Early Termination}
\label{alg:DE}
\end{algorithm}



DE evolves a {\em NewGeneration} of candidates  from
a current {\em Population}.  Our DE's lose one ``life''
when the new population is no better than  current one (terminating when ``life'' is zero)$^{L4}$.
Each candidate solution in the {\em Population}  
is a pair of {\em (Tunings, Scores)}.  {\em Tunings} are selected from
{parameters} and {\em Scores} come from training a learner using those parameters
and applying it     test data$^{L23-L27}$.

The premise of DE  is that the best way to mutate the existing tunings
is to {\em Extrapolate}$^{L28}$
between current solutions.  Three solutions $a,b,c$ are selected at random.
For each tuning parameter $i$, at some probability {\em cr}, we replace
the old tuning $x_i$ with $y_i$. For booleans, we use $y_i= \neg x_i$ (see line 36). For numerics, $y_i = a_i+f \times (b_i - c_i)$   where $f$ is a parameter
controlling  cross-over.  The {\em trim} function$^{L38}$ limits the new
value to the legal range min..max of that parameter.
 
The main loop of DE$^{L6}$ runs over the {\em Population}, replacing old items
with new {\em Candidate}s (if  new candidate is better).
This means that, as the loop progresses, the {\em Population} is full of increasingly
more valuable solutions. This, in turn, also improves  the candidates, which are {\em Extrapolate}d
from the {\em Population}.

For the experiments of this paper, we collect performance
values from SVM, from which a {\em Goal} function extracts one 
performance value$^{L26}$ (so we run this code many times, each time with
a different {\em Goal}$^{L1}$).  Technically, this makes a  {\em single objective} DE 
(and for notes on multi-objective DEs, see~\cite{robivc2005demo,zhang2007moea,huang2010differential}).


