\documentclass[sigconf,review, anonymous]{acmart}
\acmConference[ESEC/FSE 2017]{Submitted to 11th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering}{4--8 September, 2017}{Paderborn, Germany}

\usepackage{booktabs} % For formal tables
\usepackage{algorithm, algorithmicx} % pseudo code
\usepackage{algpseudocode}% pseudo code
\usepackage{multirow}
\usepackage{tabu}
\usepackage{enumitem} % handle itemize, enumerate 


\captionsetup{belowskip=2pt,aboveskip=2pt} % space between caption and content



%##############Another result box
\usepackage[framemethod=tikz]{mdframed}
\usepackage{lipsum}
\usetikzlibrary{shadows}
\usepackage{mathtools}
\usepackage{balance}
\usepackage{graphics}
\newmdenv[
tikzsetting= {fill=white},
linewidth=1pt,
roundcorner=2pt, 
shadow=false
]{myshadowbox}

%########## Result Box##########
\usepackage{color,colortbl}
\usepackage{xcolor}
\definecolor{lightgray}{gray}{0.8}

\makeatletter
\let\th@plain\relax
\makeatother

\usepackage[framed]{ntheorem}
\usepackage{framed}
\usepackage{tikz}
\usetikzlibrary{shadows}

\definecolor{Gray}{rgb}{0.88,1,1}
\definecolor{Gray}{gray}{0.85}
\theoremclass{Lesson}
\theoremstyle{break}
\tikzstyle{thmbox} = [rectangle, rounded corners, draw=black,
 fill=Gray,  drop shadow={fill=black, opacity=1}]
\newcommand\thmbox[1]{%
 \noindent\begin{tikzpicture}%
 \node [thmbox] (box){%
\begin{minipage}{.94\textwidth}%    
     \vspace{-1mm}#1\vspace{-1mm}%
   \end{minipage}%
 };%
 \end{tikzpicture}}
 

\newcommand{\wei}[1]{\textcolor{red}{Wei: #1}} 
\newcommand{\Menzies}[1]{\textcolor{red}{Dr.Menzies: #1}} 
 




%% timm tricks
\newcommand{\bi}{\begin{itemize}[leftmargin=0.4cm]}
\newcommand{\ei}{\end{itemize}}
\newcommand{\be}{\begin{enumerate}}
\newcommand{\ee}{\end{enumerate}}
\newcommand{\tion}[1]{\S\ref{sect:#1}}
\newcommand{\fig}[1]{Figure~\ref{fig:#1}}
\newcommand{\tab}[1]{Table~\ref{tab:#1}}
\newcommand{\eq}[1]{Equation~\ref{eq:#1}}

\let\theoremframecommand\thmbox
\newshadedtheorem{lesson}{Result}



% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
% \acmDOI{10.475/123_4}

% ISBN
% \acmISBN{123-4567-24-567/08/06}

%Conference
\acmConference[FSE'2017]{ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING}{September 2017}{PADERBORN, GERMANY} 
\acmYear{2017}
\copyrightyear{2017}

\acmPrice{15.00}


\begin{document}
\title{Always Baseline Against Simpler Methods:\\
a Case Study with Deep Learning}
% \titlenote{Produces the permission block, and
%   copyright information}
% \subtitle{Extended Abstract}
% \subtitlenote{The full version of the author's guide is available as
%   \texttt{acmart.pdf} document}


\author{Wei Fu}
% \orcid{1234-5678-9012}
\affiliation{%
  \institution{Computer Science Department, North Carolina State University}
  \streetaddress{890 Oval Drive}
  \city{Raleigh} 
  \state{North Carolina} 
  \postcode{27606}
}
\email{wfu@ncsu.edu}

\author{Tim Menzies}
\affiliation{%
  \institution{Computer Science Department, North Carolina State University}
  \streetaddress{890 Oval Drive}
  \city{Raleigh} 
  \state{North Carolina} 
  \postcode{27606}
}
\email{tim.menzies@gmail.com}
 
% \pagestyle{plain}
\begin{abstract}
Much software research makes extensive use of automatic data miners.
For example, recently    deep learning
was used to  find which
questions  in a Stack Overflow programmer discussion
forum can be linked together. 

We show that a very simple optimizer called DE (differential evolution)
can achieve  similar (and sometimes better) results 
in 10 minutes. This DE method runs very fast:
84 times faster than the 14
hours required for deep learning .

We offer these results as a cautionary tale to the software analytics community.
While deep learning is an exciting new technique, the benefits of this
method need to be carefully assessed w.r.t. its computational cost. 
More generally,
if researchers deploy some new and expensive process, that work should be baselined against some simpler and faster alternatives.
This is particularly important for deep learning since these learners need 
 hours (to  weeks) to train the model.
Such long CPU times limit the ability
of (a)~one researcher to test
the stability of their conclusion
via repeated runs with different random seeds;
or (b)~other researchers to repeat, improve, or even refute that original work.
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
% \begin{CCSXML}
% <ccs2012>
%  <concept>
%   <concept_id>10010520.10010553.10010562</concept_id>
%   <concept_desc>Computer systems organization~Embedded systems</concept_desc>
%   <concept_significance>500</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10010520.10010575.10010755</concept_id>
%   <concept_desc>Computer systems organization~Redundancy</concept_desc>
%   <concept_significance>300</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10010520.10010553.10010554</concept_id>
%   <concept_desc>Computer systems organization~Robotics</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10003033.10003083.10003095</concept_id>
%   <concept_desc>Networks~Network reliability</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
% </ccs2012>  
% \end{CCSXML}

% \ccsdesc[500]{Computer systems organization~Embedded systems}
% \ccsdesc[300]{Computer systems organization~Redundancy}
% \ccsdesc{Computer systems organization~Robotics}
% \ccsdesc[100]{Networks~Network reliability}

% We no longer use \terms command
%\terms{Theory}

\keywords{Software analytics, parameter tuning, deep learning, SVM, CNN, linkable knowledge units prediction.}


\maketitle

% \pagestyle{headings}
% \setcounter{page}{1}
%\pagenumbering{arabic} %XXX delete before submission
% \input{samplebody-conf}


\section{Introduction}


This paper extends a prior result from ASE'16 by
 Xu et al.\cite{xu2016predicting} (hereafter, XU).  That paper described
 a method to
 explore large programmer discussion forums, then 
 uncover related, but separate, entries.
 This is an important problem. Modern SE
 is evolving so fast that these  forums
 contain more relevant and recent comments on 
 current technology than any textbook or research article.
 
 In their work, XU predicted whether two questions posted on Stack Overflow are semantically linkable. 
Specifically,  a question along with its entire set of answers posted in Stack Overflow
as a {\it knowledge unit}~(KU). If two knowledge units are semantically related, they're considered
as {\it linkable} knowledge units. 
 
This paper debates what methods should be recommended
to those wishing to repeat the analysis of   XU.
In their paper, they used a convolution neural
network (a kind of deep leaner~\cite{lecun2015deep}). Such 
CNNs are highly computationally expensive,
often requiring network composed of 10 to 20 layers, hundreds of millions of weights and billions of connections between units~\cite{lecun2015deep}. Even with
advanced hardware and algorithm parallelization, training deep learning models still requires hours to weeks.
For example:
\bi
\item
XU report that their analysis
required 14 hours of CPU.
\item
Le~\cite{le2013building} used  a cluster with 1,000 machines (16,000 cores) for three days to train a deep learner.
\ei
In this work,  we focus on whether using simple and faster methods can achieve
the results that are currently achievable by the state-of-art deep learning method.
Specifically, we repeat the XU
study using  DE  (differential evolution~\cite{storn1997differential}),
which is a hyper-parameter optimization
method.
Our study asks:


{\it \textbf{RQ1}: Can we reproduce XU's baseline results (Word Embedding + SVM)?}
Using such a baseline, we can compare our methods to those of XU.
 
 {\it \textbf{RQ2}: Can   DE   tune a standard learner such that
 it outperforms
  XU's deep learning method?}
 We apply differential evolution  to tune 
Word Embedding + SVM. In terms of{precision},{ recall} and{F1-score}, we observe that this tuned SVM method outperforms CNN in most evaluation scores.

{\it \textbf{RQ3}: Is tuning SVM with DE faster than XU's deep learning method?}
Our   DE method
 is  $84$ times faster than CNN. 
 
We offer these results as a cautionary tale to the software analytics community.
While deep learner is an exciting new technique, the benefits of this
method need to be carefully assessed w.r.t. its computational cost. 
More generally,
if researchers deploy some new and expensive process (like deep learning), that work should be baselined against some simpler and faster alternatives
 

The rest of this paper is organized as follows. Section~\ref{background} describes the background and related work on deep learning and parameter tuning in SE. Section~\ref{method} explains the case study problem and proposed tuning method investigated in this study, then Section~\ref{experiment} describes the
experimental settings of our study, including research questions, data sets, evaluation measures and experimental design.
Section~\ref{results} presents the results. Section~\ref{discussion} discusses implications from the results and the threats to the validity of our study. Section~\ref{conclusion} concludes the paper and discuss the future work.
\subsection{Reproduction Package}
To enable other researchers to repeat, improve, or
refute our results, all our scripts and data are 
freely available on-line in both
Github\footnote{URL blinded for 
peer review.} and in archival format\footnote{Blinded for peer review}, tagged with a unique DOI.



\section{Background and Related Work}\label{background}

\subsection{Why Explore Faster Software Analytics?}
Researchers and industrial practitioners now routinely make extensive use of software analytics to discover (e.g.) how long it will take to integrate the new code~\cite{czerwonka2011crane}, where bugs are most likely~\cite{ostrand2004bugs}, who should fix the bug~\cite{anvik2006should}, or how long it will take to develop this code~\cite{kocaguneli2012value,kocaguneli2012exploiting,molokken2003review}.  Large organizations like Microsoft routinely practice data-driven policy development where organizational policies are learned from an extensive analysis of large data sets collected from developers~\cite{begel2014analyze,theisen2015approximating}.

But the more complex the  method,
the harder it is to apply the analysis.
Fisher et al.~\cite{fisher2012interactions} characterizes software analytics as a work flow that distills large quantities of low-value data down to smaller sets of higher value data. Due to the complexities and computational cost of SE analytics, ``the luxuries of interactivity, direct manipulation, and fast system response are gone''~\cite{fisher2012interactions}. They characterize modern cloud-based analytics as a throwback to the 1960s-batch processing mainframes where jobs are submitted and then analysts wait, wait, wait for results with ``little insight into what is really going on behind the scenes, how long it will take, or how much it is going to cost''~\cite{fisher2012interactions}. Fisher et al. ~\cite{fisher2012interactions} document the issues seen by 16 industrial data scientists, one of whom remarks \begin{quote}
``Fast iteration is key, but incompatible with the say jobs are submitted and processed in the cloud. It is frustrating to wait for hours, only to realize you need a slight tweak to your feature set''.
\end{quote}

Methods for improving the quality of modern software analytics have made the issue even more serious. There has been continuous development of new feature selection~\cite{hall2003benchmarking} and feature discovering~\cite{jiang2013personalized} techniques for software analytics, with the most recent ones focused on deep learning methods. These are all exciting innovations with the potential to dramatically improve the quality of our software analytics tools. Yet these are all CPU/GPU-intensive methods. For instance:
\bi
\item Learning control settings for learners can take days to weeks to years of CPU time~\cite{fu2016differential,tantithamthavorn2016automated,wang2013searching}.
\item Lam et al. needed weeks of CPU time to combine deep learning and text mining to localize buggy
files from bug reports~\cite{lam2015combining}.
\item Gu et al. spent $240$ hours of GPU time  to train a deep learning based method to generate API usage sequences for given natural language query~\cite{gu2016deep}. 
\ei 
Note that the above problem is not solvable by waiting for faster CPUs/GPUs. We 
can no longer rely on Moore's Law ~\cite{moore1998cramming} to double our computational power every 18 months. Power consumption and heat dissipation issues effect block further exponential increases to CPU clock frequencies~\cite{kumar2003single}. Cloud computing environments are extensively monetized so the total financial cost of training models can be prohibitive, particularly for very expensive tasks; For example, it would take 15 years of CPU time to learn the tuning parameters of software clone detectors proposed in ~\cite{wang2013searching}. Much of that CPU time is wasted if there is a faster  way.

Based on the above, we assert that 
avoiding slow methods for software analytics is an 
open and urgent issue.
% \subsection{Why not just use more of the Cloud?}
% SWAY reduces the number of evaluations required to optimize a model (and hence the CPU cost of this kind of analysis by one to two orders of magnitude). Given the ready availability of cloud-based CPU, we are sometimes asked
% {\em what are the benefits of merely making something run 100 times faster
% when we can just buy more CPU on the cloud?}
% In reply, we say that CPUs are not an unlimited resource that should be
% applied unquestionably to computationally expensive problems.
% \bi
% \item
% We can no longer rely on Moore's
% Law~\cite{658762} to double our computational power
% very 18 months.
% Power consumption and heat
% dissipation issues effectively block further
% exponential increases to CPU clock
% frequencies~\cite{kuman03}.
% \item
% Even if we could build
% those faster CPUs, we would still need to power them.
% CPU power requirements (and the
% pollution associated with generating that
% power~\cite{thib14}) is now a significant issue.
% Data centers consume 1.5\% of globally electrical
% output and this value is predicted to grow
% dramatically in the very near
% future~\cite{koomey08} (data centers in the
% USA used 91 billion kilowatt-hours of electrical
% energy in 2013, and they will be using 139 billion
% kilowatt-hours by 2020 (a 53\%
% increase)~\cite{thib14}).
% \item
% Even if (a)~we could
% build faster CPUs and even if (b)~we had the energy to
% power them and even if (c)~we could dispose of the
% pollution associated with generating that energy,
% then all that CPU+energy+pollution offset would be a service
% that must be paid for. Fisher et al.~\cite{Fisher:2012}
% comment that cloud
% computation is a heavily monetized environment that charges for all
% their services (storage, uploads, downloads, and CPU time).
% While each small part of that service is cheap, the total annual
% cost to an organization can be exorbitant.
% Google reports that a 1\%
% reduction in CPU requirements saves them millions of dollars in power costs~\cite{penix16}.
% \ei
% Hence we say that tools like SWAY, that use less CPU, as interesting because they
% let us achieve the same goals with fewer resources.

\subsection{What is Deep Learning?}

This paper explores faster ways to achieve results from
software analytics based on deep learning.
Deep learning is a branch of machine learning built on multiple layers of neural networks that attempt to model high level abstractions in data. According to LeCun et al.~\cite{lecun2015deep}, deep learning methods are representation-learning methods with multiple levels of representation,
obtained by composing simple but non-linear modules that each
transforms the representation at one level (starting with the raw input)
into a representation at a higher, slightly more abstract level. Compared to the conventional
machine learning algorithms, deep learning methods are very good at exploring high-dimensional data.

By utilizing extensive computational power, 
deep learning has been proven to be a very powerful method 
by researchers in many fields\cite{lecun2015deep}, like computer vision and natural language processing\cite{krizhevsky2012imagenet,mikolov2013distributed,sutskever2014sequence,schmidhuber2015deep,arel2010deep}. In 2012, 
Convolution neural networks method won the ImageNet competition ~\cite{krizhevsky2012imagenet},
which achieves half of the error rates of the best competing
approaches. After that, CNN becomes the dominant approach for almost all recognition
and detection tasks in computer vision community. CNNs are desgined to process the data in the form of mupltple arrays, e.g., image data. According to LeCun et al.~\cite{lecun2015deep},
recent CNN methods are usually a huge network composed of 10 to 20 layers, hundreds of millions of weights and billions of connections between units. With advanced hardware and algorithm parallelization, training such model still need a few hours~\cite{lecun2015deep}. 
For the tasks that deal with sequential data, like text and speech, recurrent neural networks~(RNNs) are working well in this situation. 
RNNs are found to be good at predicting next character and word given the context. For example, Graves et al.~\cite{graves2013speech} proposed to use long short-term memory~(LSTM) RNNs to perform speech recognition, 
which achieves $17.7\%$ on the benchmark testing data. Sutskever et al.~\cite{sutskever2014sequence} used two multiplelayered LSTM RNNs to translate sentences in English to French.




\subsection{Deep Learning in SE}

We study deep learning since, recently, it  has attracted 
much attentions from researchers and practitioners in software
 community\cite{wang2016automatically, gu2016deep, xu2016predicting,white2016deep,white2015toward,lam2015combining,choetkiertikul2016deep,yuan2014droid}.
 These researchers applied  deep learning techniques to solve various problems,
 including defect prediction, bug localization, clone code detection, malware detection, API recommendation, 
 effort estimation and linkable knowledge prediction.
 
We find that this work   can be divided into   two categories:
 
\bi
\item Treat deep learning as a feature extractor, and then apply other regular machine learning algorithms to do further job~\cite{lam2015combining,wang2016automatically,choetkiertikul2016deep}.
\item Solve problems directly with  deep learning~\cite{gu2016deep,xu2016predicting,white2016deep,white2015toward,yuan2014droid}.
\ei
\noindent
\subsubsection{Deep Learning as  Pre-Processor:}

Lam et al.~\cite{lam2015combining}  proposed an approach to apply deep neural network
 in combination with rVSM to automatically locate the potential buggy files for a given
 bug report. By comparing it to baseline methods~(Naive Bayes~\cite{kim2013should}, learn-to-rank\cite{ye2014learning}, 
 BugLocator~\cite{zhou2012should}), Lam et al. reported,$16.2-46.4\%$, $8-20.8\%$  and $2.7-20.7\%$ 
 higher top-1 accuracy than baseline methods, respectively~\cite{lam2015combining}. The training time for deep neural
 network was reported from 70 to 122 minutes on a computer with 32 cores 2.00GHz CPU,
 126 GB memory machine. However,
 the runtime information of the baseline methods was reported.
 
 Wang et al.~\cite{wang2016automatically} applied deep belief network to automatically
 learn semantic features from token vectors extracted from the studied software program. After
 applying deep belief network to generate features from software code,
 Naive Bayes, ADTree and Logistic Regression methods are used to evaluate the effectiveness
 of feature generation. In terms of
 runtime, Wang et al. only report time for generating semantics features with deep belief network, which
 ranged from 8 seconds to 32 seconds~\cite{wang2016automatically}. However, the time for training and tuning deep belief network is
 missing. Furthermore, to compare the effectiveness of deep belief network for generating features with extracting traditional 
 static code features(e.g.  McCabe metrics, Halstead's effort metrics and  CK object-oriented code mertics~\cite{kafura1987use,chidamber1994metrics,mccabe1976complexity,halstead1977elements} )in terms of time cost, 
 it would be favorable to include all the time spent on feature extraction, including
 paring source code, token generation and token mapping.
 
 Choetkiertikul et al.~\cite{choetkiertikul2016deep} proposed to apply deep learning techniques
 to solve effort estimation problems on user story level. 
 Specifically,  Choetkiertikul et al.  proposed to levearge
 long short-term memory~(LSTM) to learn feature vectors from the title,
 description and comments associated with an issue report and
 regular machine learning techniques, like CART, Random Forests, 
 Linear Regression and Case-Based Reasoning are applied afterwards.
 LSTM is reported to have a 
 significant improvement over the baseline method bag-of-word.
 However, no further information regarding
 runtime as well as hardware  was reported for both methods.
 
 
\noindent
\subsubsection{Deep Learning as  a Problem Solver:}

 White et al.~\cite{white2015toward, white2016deep} applied
 recurrent neural networks, one type of  deep learning techniques, 
 to address code clone detection and code suggestion. As they reported,
 the average training time for 8 projects were ranging from 34 seconds
  to 2977 seconds for each epoch on a two 3.3 GHz
 CPUs computer and each project required at least 30 epochs~\cite{white2016deep}.
 For the {\it JDK} project in their experiment, it would take 25 hours 
 on the same computer to train the models before getting prediction.
 For the time cost for code suggestions, authors did not mention any related information~\cite{white2015toward}.

Gu et al.~\cite{gu2016deep} proposed  a recurrent neural network~(RNN)
 based method, D{\scriptsize EEP}API, to generate API usage sequences for a given natural language query. 
 Compared with the baseline method { SWIM}~\cite{raghothaman2016swim} and 
 { Lucene + UP-Miner}~\cite{wang2013mining},  D{\scriptsize EEP}API   improved the performance significantly.
 However, that improvement came at a cost: that  model was trained with a Nivdia K20 GPU for  240 hours.
 
 XU~\cite{xu2016predicting} utilized neural language model and  
 convolution neural network~(CNN) to  learn word-level and document-level features to
 predict semantically linkable knowledge units in Stack Overflow. 
 In terms of performance metrics, like precision, recall and F1-score,
 CNN method was evaluated much better than 
 the baseline method support vector machine~(SVM). 
 However, once again, that performance improvement came at a cost:
 their deep learner required  
 14 hours to train CNN model on a 2.5GHz PC with 16 GB RAM.
 
 Yuan et al.~\cite{yuan2014droid} proposed a deep belief network based method for
 malware detection on Android apps. By training and testing
 the deep learning model with  200 features extracted
 from static analysis and dynamic analysis from 500 sampled Andorid app, they
 got $96.5\%$ accuracy for deep learning method  and $80\%$ for SVM.
 However, they did not report any runtime comparison between deep learning method and 
 other classic machine learning methods.
 
 
 \subsubsection{Issues with Deep Learning:}
 In summary,  deep learning is used extensively in software
 engineering community.  A common pattern
 in that research is to:
 \bi
 \item
 Report DL's benefits, but not   its CPU cost\cite{white2016deep,white2015toward,lam2015combining,choetkiertikul2016deep,yuan2014droid};
 \item
 Or simply show
 the cost, without comment\cite{wang2016automatically, gu2016deep, xu2016predicting}.
 \ei
Since  deep learning techniques cost large amount of time and computational
resources to train its model,
one might ask question whether the improvements from deep learning is worth
the costs. {\it Are there any simple techniques that achieve similar improvements
with less resource costs?} To investigate how simple methods could improve baseline
methods, we select XU\cite{xu2016predicting} study as a case study. The reason
is as follows:
\bi 
\item Many deep learning methods are impractically slow
to run enough times to obtain statistically significant results.
\item
Further, it is not
yet common practice for DL researchers
to share their implementations and data~\cite{white2016deep,white2015toward,lam2015combining,wang2016automatically,choetkiertikul2016deep,gu2016deep}, where a tinny difference may lead to a huge difference in the results.
\item Some studies do not report their runtime and experimental environment, which makes it harder for us
to systematically compare our results with theirs~\cite{choetkiertikul2016deep,yuan2014droid,white2015toward, white2016deep}.
\ei
This paper explore the  XU work since it
is simple to implement and the training and testing data is public available.




% In this paper, we revisit the research problems 
% from XU\cite{xu2016predicting} work, and by applying parameter tuning 
% to SVM algorithms, we find that the results we've got, on average, are even 
% better than their CNN results with quite less training and tuning time.
% Specifically, SVM with optimal tunings have won over deep learning 
% in $\frac{8}{12}$ performance scores and for those $\frac{4}{12}$,
% tuned SVM  does not lose much. However, CNN took 14 hours to achieve
% those scores and parameter tuning only require 10 minutes, which is almost 80X faster.


\subsection{Parameter Tuning in SE}
In this paper, we use parameter tuning to
achieve results that are competitive with deep learning. This section
discusses related work on parameter tuning.


Machine learning algorithms are designed to explore the instances
to learn the bias. However, most of these algorithms are controlled by parameters
such as:
\bi
\item
The maximum allowed depth
of decision tree built by CART;
\item
The number of trees to be built within a random forest.
\ei
Adjusting these parameters
is called hyperparameter optimziation.
It is a well   well explored approach in other communities \cite{bergstra2012random,li2016hyperband}. However, in SE,
such parameter optimization is not a common tasks~(as shown in the following examples).



%%%%%%%%%%%%%%%% list of parameters%%%%%%%%%%%%%%%%%%%%%
%\renewcommand\arraystretch{1.2}
\begin{table*}[htp]
%\scriptsize
   \caption {List of Parameters Tuned by This Paper.}
\centering
\resizebox{\textwidth}{!}{
	\begin{tabular}{|c|c|c|c|l|}
	\cline{1-5}
	Parameters & Default &Xue et al.&Tuning Range& 
\multicolumn{1}{c|}{Description} \\ \hline
	C & 1.0 &unkown&[1, 50]& Penalty parameter C of the error term.\\ \cline{1-5} 
	 kernel & `rbf' &`rbf'&[`liner',`poly',`rbf',`sigmoid']& Specify the kernel type to be used in the algorithms. \\ \cline{1-5} 
	 gamma & {1/n\_features} &$1/200$& [0, 1]& Kernel coefficient for `rbf', `poly' and `sigmoid'. \\ \cline{1-5} 
	 coef0 & 0 & unkown & [0, 1] &  Independent term in kernel function. It is only used in `poly' and `sigmoid'. \\ \cline{1-5}
\hline
	\end{tabular}}
\label{tab:parameters}
\end{table*}

In the arena of {\em defect prediction}, 
Fu et al.\cite{fu2016tuning}  surveyed hundreds of highly 
cited software engineering paper in area of defect prediction. 
Their observation is that most software engineering  researchers
did not acknowledged the impact of tunings 
~(exceptions: \cite{lessmann2008benchmarking,tantithamthavorn2016automated}) and
use the ``off-the-shelf''data miners. For example, 
Elish et al.\cite{elish2008predicting} compared support vector machines
to other data miners for the purposes of defect prediction.
However, the Elish et al. paper makes no mention of any SVM tuning study.

In the arena of {\em topic modeling}, Argrawa et al.\cite{agrawal2016wrong} investigated 
the impact of parameter tuning on Latent Dirichlet Allocation.
LDA 
  is a widely used technique in software engineering field
to find related topics within unstructured text, 
like topics analytics in stack overflow \cite{barua2014developers}
and source code analysis \cite{binkley2014understanding}.
 Argrawa et al. found that LDA suffers from conclusion instability
~(different input orderings can lead to very different results)
that are a result of poor choice of the LDA control parameters. 
Yet, in their survey of LDA use in SE, they found that very few  
researchers ~(4 out of 57 papers) explored the benefits of tuning

One troubling trend is that, in the few SE papers that perform tuning,
they do so using methods heavily deprecated in the machine learning community.
For example, two SE papers that use tuning~\cite{lessmann2008benchmarking,tantithamthavorn2016automated}, 
apply a simple grid search to explore the potential parameter space for optimal tunings.
~(such grid searchers run one for-loop for each parameter being optimized). 
However, Bergstra et al.\cite{bergstra2012random} and 
Fu et al.\cite{fu2016differential} argue that random search methods
~(e.g. the 
differential evolution algorithm used here) better than 
grid search in terms of efficiency and performance.
For example:
\bi
\item
Fu et al showed that finding useful tunings for software defection is remarkably fast  using DE.
\item
A similar result was reported by Argrawa et al.: DE can quickly remove
conclusion instability for LDA; and this stabler LDA algorithm has a better
classifier performance.
\ei
% In this work, parameter tuning is applied to the baseline method for Deep Learning
% to better understand how deep learning perform in terms of efficiency and performance.
% Since ~(a)tuning with DE is easy to implement and fast to run; (b) it is shown to be able
% to improve learners' performance, it will not introduce much overhead to the baseline method.

% To our best knowledge, this is the first paper
% applying parameter tuning to the baseline method for Deep learning methods in 
% software engineering community. Our results show that no further software analytics
% paper with Deep Learning just use ``off-the-shelf'' data miners as the baseline
% method to compare with. Furthermore, since Deep Learning is such a resource consuming
% technique and software analytics tasks are not extremely complicated, the cost for 
% both baseline methods and Deep learning method should be supplied.



\section{Method}\label{method}
In the following, 
we show that if Word Embedding + SVM is tuned with DE, 
performs better than the deep learner preferred by XU.
Also, that tuning and learning method is 84 times faster. 
\subsection{Research Problem}\label{problem}

This section is an overview of the the task and methods 
used by XU. Their task was to  predict relationships between two questions in Stack Overflow,  precisely, 
XU  divided linkable  units 
into {\it duplicate}, {\it direct link}, {\it indirect link} and {\it isolated}  four different categories 
based on its relatedness. The details are shown in \tab{classes}~\cite{xu2016predicting}:

%%%%%%% ================table--begin======================
\begin{table}[!htp]
\caption{Classes of Knowledge Unit Pairs.}\label{tab:classes}
\centering
% \resizebox{0.48\textwidth}{!}{
\begin{tabular}{l|l}
\hline
\rowcolor{lightgray}
Class & Description  \\\hline
\multirow{2}{*}{Duplicate} & These two knowledge units are addressing the\\
                           & same  question.\\ \hline
\multirow{2}{*}{Direct link}& One knowledge unit can help to  answer the\\ 
                         &  question in the other  knowledge unit.\\ \hline
\multirow{3}{*}{Indirect link}& One knowledge provides similar information to\\
                         &  solve the  question in the other knowledge unit, \\
                         &  but not a direct answer.\\ \hline
\multirow{2}{*}{Isolated}& These two knowledge units discuss unrelated \\
                         & questions.\\ \hline
\end{tabular}
% }
\end{table}
%%%%%% ================table--end======================

% \bi
% \item Duplicate:  these two knowledge units are addressing the same question.
% \item Direct link: one knowledge unit can help to answer the question in the other knowledge unit.
% \item Indirect link: one knowledge provide similar information to solve the question in the other knowledge unit, but not a direct answer.
% \item Isolated: these two knowledge units discuss unrelated questions.
% \ei 
In that paper, XU provided the following two methods as baselines:

\bi
\item TF-IDF + SVM: a multi-class SVM classifier with  36 textual features generated  based on the 
TF and IDF values of the words in a pair of knowledge units. 
\item Word Embedding + SVM:  a multi-class SVM classifier with word embedding generate by word2vec model~\cite{mikolov2013distributed}.
\ei
Both of these two baseline methods are compared against the proposed method, word embedding + CNN. 
Note that XU did not tune their baseline methods.



\subsection{Learners and Their Parameters}
SVM~(support vector machines) have been proven to be a very successful method to solve
text classification problem. An SVM  seeks to minimize mis-classification
errors by selecting a boundary or hyperplane that leaves
the maximum margin between positive and negative classes~(where the
margin is defined as the sum of the distances of the
hyperplane from the closest point of the two classes\cite{joachims1998text}).

Like most machine learning algorithms, there are some parameters associated with
SMV to control how it learns.  In XU's experiment, they used a radial-bias function~(RBF) for their SVM kernel
and set $\gamma$ to $1/k$, where $k$ is $36$ for TF-IDF + SVM method
and $200$ for Word Embedding + SVM method. For other parameters, 
XU mentioned that grid search was applied to optimize the SVM parameters, 
but no further information was disclosed. 

For our work, we used the SVM module from Scikit-learn~\cite{scikit-learn}, a Python package for machine learning,
where the following parameters shown in Table. ~\ref{tab:parameters} are selected for tuning.
Parameter {\it C} is to set the amount of regularization, which controls the tradeoff between
the errors on training data and the model complexity.  A small value for {\it C} will generate 
a simple model with more training errors, while a large value will lead to a complicated model with fewer
errors. {\it Kernel} is to introduce different nonlinearities into the SVM model by applying kernel functions
on the input data. {\it Gamma } defines how far the influence of a single training example reaches, 
with low values meaning `far' and high values meaning `close'. {\it coef0} is an independent parameter used
in sigmod and  polynomial kernel function.

As to why we used the ``Tuning Range'' shown in {parameters}, and not some other ranges,
we note that (a)~those ranges included the defaults and also XU's values ; (b)~the results shown below
show that by exploring those ranges,  we achieved large gains in the performance of our baseline method.
This is not to say that {\em larger} tuning ranges might not result in {\em greater} improvements.
However, for the goals of this paper (to show that tuning baseline method do matter), exploring
just these ranges shown in \tab{parameters} will suffice.


%In this work, we investigate whether parameter tunings can improve the baseline method based on XU work.
%Specifically, to compare with the proposed method Word Embedding + CNN, we choose Word Embedding + SVM
%as our baseline, where both CNN and SVM methods are supplied with the same word embedding feature data. 


\subsection{Learning Word Embedding}
Learning word embeddings refers to finding vector representations
of words such that the similarities between words can be captured by cosine similarity of corresponding 
vector representations. It is been shown that the words with similar semantic and syntactic are found closed
to each other in the embedding space~\cite{mikolov2013distributed}.

Several methods have been proposed to generate word embeddings, 
like skip-gram~\cite{mikolov2013distributed}, GloVe ~\cite{pennington2014glove}
and PCA on the word co-occurrence matrix~\cite{lebret2013word}. To replicate XU work,
we used continuous skip-gram model~(word2vec),  which is a unsupervised word representation learning method based on
neural networks. 

The skip-gram model learns vector representations of words
 by predicting the surrounding words in a context window. 
 Given a sentence of words $W =w_1$,$w_2$,...,$w_n$, the objective of skip-gram model is to maximize the
 the average log probability of the surrounding words:
 \begin{equation*}
 \frac{1}{n}\sum_{i=1}^{n} \sum_{-c\leq j \leq c, j \neq 0} log p(w_{i+j}|w_i)
\end{equation*}
where $c$ is the context window size and $w_{t+j}$ and $w_{t}$ represent surrounding words and center word, respectively.
The probability of $p(w_{i+j}|w_i)$ is computed according to the softmax function:

\begin{equation*}
p(w_O|w_I) = \frac{exp(v_{w_O}^Tv_{w_I})}{\sum_{w=1}^{|W|}exp(v_{w}^Tv_{w_I})}
\end{equation*}
where $v_{w_I}$ and $v_{w_O}$ are the vector representations of the input and output vectors of $w$, respectively. 
$\sum_{w=1}^{|W|}exp(v_{w}^Tv_{w_I})$  normalizes the inner product results across all the words.
To improve the computation efficiency, Mikolove et al. \cite{mikolov2013distributed} proposed
hierachical softmax and negative sampling
techniques. More details can be found in ~\cite{mikolov2013distributed}.

Skip-gram's parameters control how that algorithm
  learns   word embeddings. Those parameters include
  {\it window size} and {\it dimensionality of embedding space}. 
Zucoon et al. \cite{zuccon2015integrating} found that embedding dimensionality
and context window size have no consistent impact on retrieval model performance. However,
Yang et al.~\cite{yang2016using} showed that large context window and dimension
 sizes are preferable to improve the performance when using CNN to solve  classification tasks
 for Twitter. Since this work is to compare performance of  tuning SVM  with CNNs, where
 skip-gram model is used to generate word vector representations for both of these methods, 
 tuning parameter of skip-gram model is beyond the scope of this paper 
 (but we will explore it in future work).
 
 

To train our word2vec model, $100,000$ knowledge units tagged with ``java'' from
Stack Overflow {\it posts} table  (include titles, questions and answers)
are randomly selected as a word corpus\footnote{Without further explanation, 
all the experiment settings, including learner algorithms,
training/testing data split, etc, strictly follow XU's work. }. 
After applying proper data processing techniques proposed by XU, like
 remove the unnecessary HTML tags and keep short code snippets in
{\it code} tag, then fit the corpus into {\it gensim} word2vec module ~\cite{rehurek2010software},
which is a python wrapper over original word2vec package.

When converting knowledge units into vector representations, 
for each word $w_i$ in the post processed knowledge unit~(including title, question and answers),
we query the trained skip-gram model to get the corresponding word vector representation $v_i$.
Then the whole knowledge unit with $s$ words
will be converted to vector representation by element-wise addition, $Uv = v_i \oplus v_2 \oplus...\oplus v_s $. 
This vector representation will be used
as the input data to SVM.




\subsection{Tuning Algorithm}

A tuning algorithm is an optimizer that will drive the learner to explore
the optimal parameter in a given searching space. According to our
literature review, there are several searching algorithms used in 
SE community:{\em 
simulated annealing}~\cite{feather2002converging,menzies2007data};
 various {\em genetic algorithms}~\cite{jones1996automatic,harman2007current, arcuri2011parameter} augmented by
techniques such as {\em differential evolution}
~\cite{storn1997differential, fu2016tuning, fu2016differential,chaves2015differential,agrawal2016wrong}, 
{\em tabu search} and {\em scatter search}~\cite{beausoleil2006moss,molina2007sspmo,corazza2013using};
{\em particle swarm optimization}~\cite{windisch2007applying}; 
numerous {\em decomposition} approaches that use
    heuristics to decompose the total space into   small problems,   then apply a
    {\em response surface methods}~\cite{krall2015gale};
     {\em NSGA II} ~\cite{zhang2007multi}and {\em NSGA III}~\cite{mkaouer2014high}.


Of all the mentioned algorithms,  the simplest are simulated annealing~(SA)  and 
differential evolution~(DE), each of which can be coded in less than a page of some high-level scripting language.
 Our reading of the current literature is that there are more  advocates for
differential evolution than SA. For example,  Vesterstrom and Thomsen~\cite{Vesterstrom04} found DE to be competitive with 
 particle swarm optimization and other GAs.  DEs have already been applied before for 
 parameter tuning~(e.g. see~\cite{omran2005differential, chiha2012tuning, fu2016tuning, fu2016differential, agrawal2016wrong}) .
Therefore, in this work, we adopt DE as our tuning algorithm and 
the main steps in DE is described in \fig{optimize}.

% \begin{algorithm}[!htp]

% \scriptsize
% \begin{algorithmic}[1]
% \Require $\mathit{np} = 10$, $f=0.75$, $cr=0.3$, $\mathit{life} = 5$, $\mathit{Goal} \in \{\mathit{pd},f,...\}$
% \Ensure $\mathit{S_{best}}$
% \vspace{2mm}
% \Function{DE}{$\mathit{np}$, $f$, $cr$, $\mathit{life}$, $\mathit{Goal}$}
%  \State $\mathit{Population}  \gets $ InitializePopulation($\mathit{np}$)   
%  \State $\mathit{S_{best}} \gets $GetBestSolution($\mathit{Population}$)
%  \While{$\mathit{life} > 0$}
%     \State $NewGeneration \gets \emptyset$
%     \For{$i=0 \to \mathit{np}-1$}
%         \State $\mathit{S_i} \gets$ Extrapolate($\mathit{Population [i], Population , cr, f}$)
%         \If {Score($S_i$) $>$Score($\mathit{Population [i]}$)}
%             \State $\mathit{NewGeneration}$.append($\mathit{S_i}$)
%         \Else
%         \State $\mathit{NewGeneration}$.append($\mathit{Population [i]}$)
%         \EndIf
%     \EndFor
%     \State $\mathit{Population  \gets NewGeneration}$
%     \If{$\neg$ Improve($\mathit{Population} $)}
%         \State $\mathit{life -=1}$
%     \EndIf
%     \State $\mathit{S_{best} }\gets$ GetBestSolution($\mathit{Population} $)
%  \EndWhile
% \State \Return $\mathit{S_{best}}$
% \EndFunction
% \Function{Score}{$\mathit{Candidate}$}
%   \State set tuned parameters according to $\mathit{Candidate}$
%   \State $\mathit{model} \gets$TrainLearner()
%   \State $\mathit{result} \gets$TestLearner($\mathit{model}$)   
%   \State \Return$\mathit{Goal}(\mathit{result})$  
% \EndFunction
% \Function{Extrapolate}{$\mathit{old, pop, cr, f}$}
%   \State $\mathit{a, b, c}\gets threeOthers(\mathit{pop,old})$  
%   \State $\mathit{newf }\gets \emptyset$
%   \For{$i=0 \to \mathit{np}-1$}
%         \If{$\mathit{cr < random()}$}
%             \State $\mathit{newf}$.append($\mathit{old[i]}$)
%         \Else
%             \If{typeof($\mathit{old[i]}$) == bool}
%                 \State $\mathit{newf}$.append(not $\mathit{old[i]}$)
%             \Else
%                 \State $\mathit{newf}$.append(trim($i$, ($\mathit{a[i]+f*(b[i]-c[i]}$)))) 
%          \EndIf
%       \EndIf
%   \EndFor
%  \State \Return $\mathit{newf}$
% \EndFunction
% \end{algorithmic} 
% \caption{Pseudocode for DE with Early Termination}
% \label{alg:DE}
% \end{algorithm}



  \begin{figure}[!h]\small
     \begin{tabular}{|p{.95\linewidth}|}\hline
      1. Given a model~(e.g., SVM) with $n$ decisions~(e.g., $n=4$),
      TUNER calls SAMPLE $N=10*n$ times.
      Each call generates one member of the population {\em pop$_{i\in N}$}.

      2. TUNER scores each {\em pop}$_i$ according to various objective
      scores $o$. In the case of our tuning SVM, the objective $o$ is to maximize
     {F1-score}

     3. TUNER tries to each replace {\em pop}$_i$ with a mutant $m$
     built using Storn's differential evolution method~\cite{storn1997differential}.
     DE extrapolates between three other members of population $a,b,c$.
     At probability $p_1$, for each decision $a_k \in a$, then
     $m_k= a_k \vee ~(p_1 < \mathit{rand}() \wedge( b_k \vee c_k))$.

     4. Each mutant $m$ is assessed by calling  $\text{EVALUATE}(\textit{model, prior=m})$;
     i.e. by seeing what can be achieved within a goal after first assuming
     that $\textit{prior}=m$.

     5. To test if the mutant $m$ is preferred to {\em pop}$_i$, TUNER simply
      compare SCORE($m$) with SCORE({\em pop}$_i$). In case of our tuning SVM,
      the one with higher score will be kept.

    6. TUNER repeatedly loops over the population, trying to replace  items with mutants, until new better mutants stop being found.

    7. Return the best one in the population as the optimal tunings.
    \\\hline
    \end{tabular}
    \caption{Procedure TUNER: strives to find ``good'' tunings which maximizes
     the objective score of the model on training and tuning data. TUNER is based on Storn's differential evolution optimizer~\cite{storn1997differential}.}
    \label{fig:optimize}
\end{figure}

% DE evolves a {\em NewGeneration} of candidates  from
% a current {\em Population}.  Our DE's lose one ``life''
% when the new population is no better than  current one (terminating when ``life'' is zero)$^{L4}$.
% Each candidate solution in the {\em Population}  
% is a pair of {\em (Tunings, Scores)}.  {\em Tunings} are selected from
% {parameters} and {\em Scores} come from training a learner using those parameters
% and applying it     test data$^{L23-L27}$.

% The premise of DE  is that the best way to mutate the existing tunings
% is to {\em Extrapolate}$^{L28}$
% between current solutions.  Three solutions $a,b,c$ are selected at random.
% For each tuning parameter $i$, at some probability {\em cr}, we replace
% the old tuning $x_i$ with $y_i$. For booleans, we use $y_i= \neg x_i$ (see line 36). For numerics, $y_i = a_i+f \times (b_i - c_i)$   where $f$ is a parameter
% controlling  cross-over.  The {\em trim} function$^{L38}$ limits the new
% value to the legal range min..max of that parameter.
 
% The main loop of DE$^{L6}$ runs over the {\em Population}, replacing old items
% with new {\em Candidate}s (if  new candidate is better).
% This means that, as the loop progresses, the {\em Population} is full of increasingly
% more valuable solutions. This, in turn, also improves  the candidates, which are {\em Extrapolate}d
% from the {\em Population}.

% For the experiments of this paper, we collect performance
% values from SVM, from which a {\em Goal} function extracts one 
% performance value$^{L26}$ (so we run this code many times, each time with
% a different {\em Goal}$^{L1}$).  Technically, this makes a  {\em single objective} DE 
% (and for notes on multi-objective DEs, see~\cite{robivc2005demo,zhang2007moea,huang2010differential}).


 \begin{figure*}
    \centering
%    \includegraphics[width=0.48\textwidth,height=2.7in]{pic/workflow.pdf} % THIS IS FOR SINGLE COLUM
     \includegraphics[width=\textwidth]{pic/workflow.pdf} % THIS IS FOR SINGLE COLUM
    \caption{The Overall Workflow of Building Knowledge Units Predictor with Tuned SVM}
    \label{fig:workflow}
\end{figure*}

\section{Experiment Design}\label{experiment}
\subsection{Research Questions}\label{RQ}
 To systematically investigate whether tuning can improve the 
 performance of baseline methods compared with deep learning method, we set
 the following three research questions:
 

 
 \bi
 \item {\it \textbf{RQ1}: Can we reproduce XU's baseline results (Word Embedding + SVM)?}
 \item {\it \textbf{RQ2}: Can   DE   tune a standard learner such that
 it outperforms XU's deep learning method?}
 \item {\it \textbf{RQ3}: Is tuning SVM with DE faster than XU's deep learning method?}
 \ei
 
 RQ1 is to investigate whether our implementation of wordbedding +SVM method has
 the similar performance with XU's baseline, which makes sure that our following 
 analysis can be generalized to XU's conclusion. RQ2 and RQ3 lead us to
 investigate whether tuning SVM comparable with XU's deep learning from both 
 performance and cost aspects.
 


\subsection{Dataset and Experimental Settings}
Our experimental data comes from Stack Overflow data dump of 
September 2016\footnote{https://archive.org/details/stackexchange},
where {\it posts} table includes all the questions and answers posted on Stack Overflow
up to date and the {\it postlinks} table describes the relationships between posts, 
e.g., {\it duplicate} and {\it linked}. As mentioned in Section
\ref{problem}, we have four different types of relationships in knowledge units.
Therefore,  {\it linked} type is further divided into {\it indirectly linked} and {\it directly linked}.
Overall, four different types of data are generated according the following rules:
\bi
\item Randomly select a pair of posts from the {\it postlinks} table, if the value
in  {\it PostLinkTypeId} field for this pair of posts is $3$, then this pair of posts is {\it duplicate} posts. 
Otherwise they're {\it directly linked} posts.

\item Randomly select a pair of posts from the {\it posts} table, if this pair of posts is linkable from each other according to
{\it postlinks} table and the distance between them are greater than 2, then this pair of posts is indirectly linked. If they're
not linkable, then this pair of posts is {isolated}.
\ei

In this work, we use the same training and testing
knowledge pairs as in~\cite{xu2016predicting}\footnote{https://github.com/XBWer/ASEDataset}, 
where 6,400 pairs of  knowledge units for training and 1,600 pairs for testing. And each type 
of linked knowledge units accounts for $1/4$ in both training and testing data. The reasons are:
\bi
\item It is to insure that  performance of our baseline method are as closed to XU's as possible.
\item Since deep learning method is way complicate compared with SVM and a little difference in implementations
might lead to different results, to fairly compare with Xu et al's result, we can use the  performance scores
of CNN method from~\cite{xu2016predicting} without any implementation bias introduced.
\ei

For training word2vec model, we randomly select 100,000 knowledge
 units~(title, question body and all the answers) from {\it posts} table that are
 related to ``java''. After that, all the training/tuning/testing knowledge units
 used in this paper are converted into word embedding representations by looking up
 each word in wrod2vec model.
 
As seen in \fig{workflow}, instead of using all the 6,400 knowledge units as training data, 
we split the original training data into { new training data} and{tuning data}, which are
used during parameter tuning procedure for training SVM and evaluating candidate
parameters offered by DE. Afterwards, the{new training} data is again fitted into the SVM
with the optimal parameters found by DE and finally  the performance of the tuned
SVM will be evaluated on the {testing data}.

To reduce the potential variance caused
by how the original training data is divided, {\it 10-fold cross-validation} is performed, where
each time one fold with $640$ knowledge units paris as the tuning data, and the remaining folds with $5760$
knowledge units as  the new training data, then the output SVM model will be evaluated on the testing data. Therefore,
all the performance scores reported below are averaged values over 10 runs.



\subsection{Evaluation Metrics}
When evaluating the performance of tuning SVM on the
multi-class linkable knowledge units prediction problem,
consistent with XU\cite{xu2016predicting}, we use accuracy, precision, recall and F1-score
as the evaluation metrics.

\begin{table}[htp]
\caption {Confusion Matrix.}
\scriptsize
\resizebox{0.45\textwidth}{!}{
\begin{tabular} {@{}cc|c|c|c|c|l@{}}
\cline{3-6}
& & \multicolumn{4}{ c| }{Classified as} \\ \cline{3-6}
& & $C_1$ & $C_2$ & $C_3$ & $C_4$ \\ \cline{1-6}
\multicolumn{1}{ |c  }{\multirow{4}{*}{Actual} } &
\multicolumn{1}{ |c|| }{$C_1$} & $c_{11}$ & $c_{12}$  & $c_{13}$ & $c_{14}$  & \\ \cline{2-6}
\multicolumn{1}{ |c  }{}                        &
\multicolumn{1}{ |c|| }{$C_2$} & $c_{21}$& $c_{22}$ & $c_{23}$ & $c_{24}$ &  \\ \cline{2-6}
\multicolumn{1}{ |c  }{}                        &
\multicolumn{1}{ |c|| }{$C_3$} & $c_{31}$ & $c_{32}$ & $c_{33}$ & $c_{34}$ & \\ \cline{2-6}
\multicolumn{1}{ |c  }{}                        &
\multicolumn{1}{ |c|| }{$C_4$} & $c_{41}$ & $c_{42}$ & $c_{43}$ & $c_{44}$ & \\ \cline{1-6}
\end{tabular}}

\label{tab:confusion}
\end{table}

Given a multi-classification problem with true labels $C_1$, 
$C_2$, $C_3$ and $C_4$, we can generate a confusion matrix like \tab{confusion}, 
where the value of $c_{ii}$ represents the number of instances that are correctly classified
by the learner for class $C_i$. 

{\it Accuracy} of the learner is defined as the number of  correctly
classified knowledge units over the total number of knowledge units, i.e.,


{\[
\begin{array}{ll}
accuracy = \frac{\sum_i c_{ii}}{\sum_{i}\sum_{j}c_{ij}}
\end{array}
\]}
where ${\sum_{i}\sum_{j}c_{ij}}$ is the total number of knowledge units.
For a given type of knowledge units, $C_j$, the  precision is defined as probability of
predicted knowledge units pairs over the actual number of knowledge unit pairs and
 recall is the percentage of knowledge unit pairs correctly classified. Mathematically,
  precision, recall and  F1-score of 
the learner can be denoted as follows:

{\[
\begin{array}{ll}
prec_j &= precision_j = \frac{n_{jj}}{\sum_{i}n_{ij}}\\
pd_j &= recall_j = \frac{n_{jj}}{\sum_{i}n_{ji}}\\ 
F1_{j} &= 2*pd_j*prec_j/(pd_j + prec_j)
\end{array}
\]}
Where ${\sum_{i}n_{ji}}$ is the actual number of knowledge units in class $C_j$
and $\sum_{i}n_{ij}$ is the predicted number of knowledge units in class $C_j$.


Recall from Algorithm~1 that we call differential evolution once for each
optimization goal. Generally, this goal depends on which metric is most important for
the business case. In this work, we use $F1$ as the score because it controls
the trade-off between precision and recall, which is also consistent with XU\cite{xu2016predicting}
and is also widely used in software engineering
community to evaluate classification results\cite{wang2016automatically,menzies2007data,fu2016tuning,kim2008classifying}.


\section{Results}\label{results}
In this section, we present our experimental results. To answer research questions raised in
Section~\ref{RQ}, we conducted two experiments:
\bi
\item
Compare   Word Embedding + SVM using Xu's code and our code;
\item
Compare our tuning SVM method with Xu's CNN.
\ei
Since we used the same training and testing data set provide by Xu
et al.\cite{xu2016predicting} and conducted our experiment in the same procedure and metrics, we simply used the results reported in the work by XU\cite{xu2016predicting} for performance comparison. 










%%%% baseline comparision %%%%%%
%\begin{table}[!htp]
%%\renewcommand{\baselinestretch}{0.35}
%%\scriptsize
%\centering
%  \caption{Comparison of our baseline method with Xu et al's }
%\resizebox{0.47\textwidth}{!}{
%  \begin{tabular} {@{}r|c c|c c|c c|c c@{}}
%   & \multicolumn{2}{c|}{Precision}  & \multicolumn{2}{c|}{Recall} &  \multicolumn{2}{c|}{F1-score} & \multicolumn{2}{c}{Accuracy}\\
%    \cline{2-9}
%    & Ours  &  \cite{xu2016predicting} & Ours  &  \cite{xu2016predicting}  &  Ours  &\cite{xu2016predicting} & Ours  &\cite{xu2016predicting}\\
%    \hline
%    Duplicate & 0.736  &0.611 & 0.550&0.725  &0.629&  0.663  &0.550&  -\\
%    Direct Link & 0.521 &0.560 & 0.502& 0.433  &0.511&  0.488& 0.402&  - \\
%    Indirect Link & 0.793  &0.787& 0.970&0.980  &0.873& 0.873  &0.970&  -\\
%    Isolated & 0.606  &0.676& 0.645 &0.538   &0.625&  0.600 & 0.645&  -\\
%    Overall & 0.664  &0.658&0.667&0.669   &0.660&  0.656 & 0.667&  0.669\\
%  \end{tabular}}
%\label{tab:baseline}
%\end{table}

\textbf{RQ1: Can we reproduce XU's baseline results (Word Embedding + SVM)?}
 
 


This first question   is    important to our work since, without the original tool released by Xu et al,
we need to insure that  our reimplementation of their baseline method~(WordEmbedding + SVM) has a similar performance to their work.
Accordingly, we carefully follow XU's procedure\cite{xu2016predicting}. We 
use the SVM learner from scikit-learn setting $\gamma = \frac{1}{200}$ and $kernel= $``rbf''. After that, the same training and testing knowledge unit pairs are applied.


\begin{table}[!htp]
\centering
\caption{Comparison of Our Baseline Method with XU's}
\resizebox{0.48\textwidth}{!}{
\begin{tabular} {@{}l l  c c  c c c@{}}
\hline
   \multirow{2}{*}{Metrics} &  \multirow{2}{*}{Methods} &  \multirow{2}{*}{Duplicate} &  
   \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Direct \\ Link\end{tabular}} &
   \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Indirect \\ Link\end{tabular}} & 
   \multirow{2}{*}{Isolated} &  \multirow{2}{*}{Overall} \\ \\ \hline
   \multirow{2}{*}{Precision}
    & Our SVM &\textbf{0.724} &0.514 & 0.779 &0.601& 0.655 \\
   & Xu's SVM &0.611 &\textbf{0.560} &\textbf{0.787}&\textbf{0.676}&\textbf{0.659} \\ \hline
   \multirow{2}{*}{Recall} 
   & Our SVM & 0.525& \textbf{0.492} & 0.970 & \textbf{0.645}  & 0.658 \\ 
   & Xu's SVM  & \textbf{0.725} &0.433    &\textbf{0.980}  & 0.538 &\textbf{0.669}  \\ \hline
   \multirow{2}{*}{F1-score}
   & Our SVM & 0.609 &  \textbf{0.503} &0.864  &  \textbf{0.622}&0.650 \\ 
   & Xu's SVM & \textbf{0.663} &  0.488  & \textbf{0.873} &  0.600 &\textbf{0.656} \\ \hline
   \multirow{2}{*}{Accuracy} 
   &  Our SVM&0.525  &  0.493 & 0.970 & 0.645 &0.658 \\
   & Xu's SVM & - &  -  &- &  - &\textbf{0.669} \\ \hline
 \end{tabular}}
\label{tab:baseline}
\end{table}

\begin{figure}[!htp]
    \centering
     \includegraphics[width=0.49\textwidth]{pic/OurSVM-Xu'sSVM.pdf} % THIS IS FOR SINGLE COLUM
    \caption{Score Delta between Our SVM with Xu's SVM in ~\cite{xu2016predicting} in terms of Precision, Recall and F1-score.}
    \label{fig:OurSVM-Xu'sSVM}
\end{figure}






 \tab{baseline}  and \fig{OurSVM-Xu'sSVM} show the performance scores and corresponding score delta between our baseline method with
 XU's in terms of accuracy, precision, recall and F1-score. As we can see, 
 when predicting these four different types of relatedness between knowledge unit pairs,
 our Word Embedding + SVM method has  very  similar performance scores to the baseline method
 reported by Xu et al in ~\cite{xu2016predicting}, with the maximum difference less than $0.2$.  
 Except for { Duplicate} type, where our baseline 
has a higher precision~(i.e., $0.724$ v.s. $0.611$) but a lower  recall (i.e., $0.525$ v.s.$0.725$). 

\fig{OurSVM-Xu'sSVM} presents the same results in a graphical format.
Any bar above zero means that our implementation has a better performance score than Xu's on predicting that specific knowledge unit relatedness class. As we can see, most 
of the differences ($\frac{8}{12}$) are within 0.05 and overall performance score delta.
For this chart we conclude that:


\vskip 1ex
 \begin{myshadowbox}
Overall, our reimplementation of WordEmbedding + SVM
has very closed performance in all the evaluated metrics 
 compared to the baseline method reported in \cite{xu2016predicting}.

 \end{myshadowbox}
The significance of this conclusion is that, moving forward,
we can  use the performance of our  reimplementation as  a valid surrogate for
the work of XU.

\begin{table}[!htp]
\centering
\caption{Comparison of Tuned SVM with Xu's CNN method. }
\resizebox{0.48\textwidth}{!}{
\begin{tabular} {@{}l l  c c  c c c@{}}
\hline
   \multirow{2}{*}{Metrics} &  \multirow{2}{*}{Methods} &  \multirow{2}{*}{Duplicate} &  
   \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Direct \\ Link\end{tabular}} &
   \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Indirect \\ Link\end{tabular}} & 
   \multirow{2}{*}{Isolated} &  \multirow{2}{*}{Overall} \\ \\ \hline
  \multirow{3}{*}{Precision} 
 % & Our SVM &0.736 &0.521 & 0.793 &0.606& 0.664 \\
   & Xu's SVM&0.611 &0.560 &0.787&0.676&0.658 \\ 
   & Xu's CNN&\textbf{0.898} & 0.758&0.840 &0.890 &0.847 \\
   & Tuned SVM&0.885 & \textbf{0.851}&\textbf{0.944} &\textbf{0.903} &\textbf{0.896}\\ \hline
   \multirow{3}{*}{Recall} 
   %& Our SVM & 0.550& 0.502 & 0.970 & 0.645  & 0.667 \\ 
   & Xu's SVM& 0.725 &0.433    &0.980  & 0.538 &0.669  \\
   & Xu's CNN& \textbf{0.898}&\textbf{0.903}    &0.773  & 0.793 &0.842  \\ 
   & Tuned SVM& 0.860 &0.828    &\textbf{0.995}  & \textbf{0.905} &\textbf{0.897}  \\  \hline
   \multirow{3}{*}{F1-score}
   %&Our SVM & 0.629 &  0.511 &0.873  &  0.625&0.660 \\ 
   & Xu's SVM& 0.663 &  0.488  & 0.873 &  0.600 &0.656 \\ 
   & Xu's CNN& \textbf{0.898} &  0.824  & 0.805 &  0.849 &0.841 \\
   & Tuned SVM& 0.878 & \textbf{ 0.841}  &\textbf{ 0.969} &  \textbf{0.909} &\textbf{0.899} \\\hline
%   \multirow{2}{*}{Accuracy} &  Our SVM&0.550  &  0.402 & 0.970 & 0.645 &0.667 \\
 %  & Xu's SVM& - &  -  &- &  - &0.669 \\ \hline
 \end{tabular}}
\label{tab:RQ2}
\end{table}
 
 

 
\textbf{RQ2: Can DE tune a standard learner such that it outperforms XU's deep learning method?}

To answer this question, we run the worklfow of \fig{workflow}, where DE is applied to 
find the optimal parameters for SVM based on the training and tuning data. Then the optimal tunings
applied on the SVM model and evaluate the built learner on testing data. Note that, in this study,
since we mainly focus on{precision},{recall} and{F1-score} measures and{F1-score} is the
harmonic mean of{precision} and{recall}, we use{F1-score} as the tuning goal for DE.
In other words, when tuning parameters,  DE expects to find a pair of candidate parameters that maximize
{\it F1-score}. 
%For CNN method, we simply adopt the Xu et al's results in ~\cite{xu2016predicting} because(1)deep learning method is not as easy as implementing SVM method, where a little difference in the structure might lead to significant result;(2) we are evaluating the learners with the same measures and use the same training and testing data.


\tab{RQ2} presents the performance scores of  Xu et al's baseline, Xu et al's CNN method and Tuned SVM 
for all metrics. The highest score for   KU pair
  is marked in shown in bold.  Note that:
\bi
\item
Without tuning, Xu et al's CNN method outperforms
the baseline SVM in $\frac{10}{12}$ evaluation metrics across all 4 classes. 
The largest performance improvement is $0.47$ for{recall} on{Direct Link} class. Note that this result is consistent with XU's conclusion
that their CNN method is superior to standard SVM.
\item
After tuning SVM, the deep learning method has no such advantage.
\ei
\fig{TunedSVM-CNN} 
 shows the score delta between tuned SVM and CNN method. Any bar above zero indicates that tuned SVM has a better performance score than CNN.
In this figure:
\bi
\item
CNN has a slightly better performance on{Duplicate} class for{precision},{\it recall} and{F1-score} and a higher{recall} on{Direct link} class. 
\item
Even when CNN performs better that our DE-based method,
the largest differences is less than $0.1$.
\item
Across all of \fig{TunedSVM-CNN},
in $\frac{8}{12}$ evaluation scores, Tuned SVM has better performance scores than CNN, with the largest deleta of $0.222$.
\ei
%and that's
%$28\%$ improvements over CNN on predicting{Indirect Link} for the{recall} %measure.

 \begin{figure}[!t]
    \centering
    \includegraphics[width=0.49\textwidth]{pic/TunedSVM-CNN.pdf} % THIS IS FOR SINGLE COLUM
    \caption{Score Delta between Tuned SVM and CNN method in terms of Precision, Recall and F1-score.}
    \label{fig:TunedSVM-CNN}
\end{figure}
 \begin{figure}[!t]
    \centering
%    \includegraphics[width=0.48\textwidth,height=2.7in]{pic/workflow.pdf} % THIS IS FOR SINGLE COLUM
     \includegraphics[width=0.49\textwidth]{pic/TunedSVM-SVM.pdf} % THIS IS FOR SINGLE COLUM
    \caption{Score Delta between Tuned SVM and Xu's SVM in terms of Precision, Recall and F1-score.}
    \label{fig:TunedSVM-SVM}
\end{figure}
 \fig{TunedSVM-SVM} compares the performance delta of tuned SVM with Xu's untuned SVM.
 We note that:
 \bi
 \item
 Tuning never   degrade SVM's performance (since there are no negative values
 in that chart).
 \item
 Tuning dramatically improves scores on predicting some classes of KU relatedness. For example, the{recall} of predicting{Direct\_link} is increased from $0.433$ to $0.903$, which is $108\%$ improvement over Xu's untuned SVM (To be fair for Xu et al, it is still $84\%$ improvement over our untuned SVM). At the same time, the corresponding{precision} and{F1} scores of predicting{Direct\_Link} are increased from $0.560$ to $0.851$ and $0.488$ to $0.841$,  which are $52\%$ and $72\%$ improvement over Xu's original report, respectively.
 \item
A similar pattern can also be observed in{Isolated} class. 
\item
Overall, tuning helps improve the performance
of SVM by $0.238$, $0.228$ and $0.227$ in terms of{precision},{recall} and{F1-score}
for all four KU relatedness classes.
\ei
Based on the performance scores in \tab{RQ2} and score delta in \fig{TunedSVM-CNN} and \fig{TunedSVM-SVM},
 we can see that:
 \bi
 \item
 Parameter tuning can dramatically improve the performance of Word Embedding + SVM~(the baseline method) for the multi-class KU relatedness prediction task;
\item
With the optimal tunings, the traditional machine learning method, SVM, if not better, is at least comparable 
 with deep learning methods (CNN).
 \ei
When discussing this result with colleagues, we are sometimes asked for a statistical
analysis that confirms the above finding.
However, 
 due the lack of evaluation score distributions of the CNN method in~\cite{xu2016predicting}, we cannot compare
their single value with our results from 10 repeated runs.
 
 Overall, the experimental results and our analysis indicate that:
 
 
\vskip 1ex
 \begin{myshadowbox}
In the evaluation conducted here,
the deep learning method, CNN, does not have any performance advantage over our tuning approach.
 \end{myshadowbox}
 

 

\textbf{ RQ3: Is tuning SVM with DE faster than XU's deep learning method?}

 
When comparing the runtime of two learning methods, it obviously should be conducted under the
 same hardware settings. 
 Since we adopt the CNN evaluation scores from ~\cite{xu2016predicting},
 we can not run on our tuning SVM experiment under the exactly same system settings.
 However, our experiment is running under a system which is similar to the one used in \cite{xu2016predicting}.
 To allow readers to have a objective comparison, we provide the experimental environment as shown in~\tab{env}. 
 To generate this table, we  recorded the start time and end time
 of the program execution, including parameter tuning, training model and testing model.
 
 \begin{table}[!htp]
\centering
\caption{Comparison of Experimental Environment  }
% \resizebox{0.48\textwidth}{!}{
\begin{tabular} {@{}l  l l l @{}}
\hline
Methods&OS&CPU&RAM \\ \hline
Tuning SVM & MacOS10.12 & Intel Core i5 2.7 GHz & 8GB  \\
CNN& Windows7 &Intel Core i7 2.5 GHz & 16GB \\
\hline
\end{tabular}
% }
\label{tab:env}
\end{table}

According to Xu et al, it took  $14$ hours to train their  CNN model
into a low loss convergence~($< e^{-3}$)~\cite{xu2016predicting}.
Our work, on the other hand
only takes takes  $10$ minutes to run SVM with parameter tuning
by DE on a similar environment.
That is, the simple parameter tuning method on SVM is $84X$ faster than  Xu's deep learning method.
% \wei{Note that the runtime shown in \tab{env} does not take account of training word2vec model.
%  The reason that we did not consider it is that both tuning SVM method and CNN method require word embedding as input.}
 
\vskip 1ex
 \begin{myshadowbox}
Compared to CNN method, tuning SVM is about $84X$ faster in terms of model building.

 \end{myshadowbox}
The significance of this finding is that, in this case study,
CNN was neither better in performance scores (see RQ2) or runtimes.
CNN's extra runtimes are a particular concern since (a) they are very long;
and (b)~these would be incurred anytime a researchers wants to update the CNN model
with new data or wanted to validate the XU result. 
 
\section{Discussion}\label{discussion}
 
\subsection{Implication}

Beyond the specifics of this case study, what general principles
can we take from the above work?

\subsubsection{Understand the task:}
One reason to try different tools for the same task is to better
understand the task.
The more we understand a task, the better we can match tools to that task. Tools that are poorly matched to task are usually complex and/or slow to execute.  In the case study of this paper, we would say that

\bi
\item
Deep learning is                   a poor match to the task of linking questions in Stack Overflow
since it is so slow;
\item
Differential evolution is a much better match since it is so fast.
\ei
That said, 
it  is important to stress that the point of this study
is not to deprecate deep learning.  
There are many scenarios were we
 believe  deep learning would be a natural
 choice (e.g. when analyzing complex speech or visual data). 
 



\subsubsection{Treat resource constraints as design challenges:}
As a general engineering principle,
we think it insightful to consider the resource cost
of a tool before applying that tool.
It turns out that this is a design pattern used in contemporary industry.
According to Calero and Pattini~\cite{calero2015green},  many current commercial  redesigns are motivated (at least in part) by arguments based on sustainability (i.e. using fewer resources to achieve results).
In fact, they say that managers used sustainability-based redesigns to 
motivate extensive cost-cutting opportunities. 

 


 
\subsection{Threads to Validity}

Threats to \textbf{internal validity} concern the consistency of the results 
obtained from the result. In our study,  to investigate how
tuning can improve the performance of baseline methods and how well
it perform compared with deep learning method, we select
Xu et al's  Word Embedding + SVM baseline method as a case study. Since the original implementation of 
Word Embedding + SVM (baseline 2 method in \cite{xu2016predicting}) is not 
publicly available, we have to reimplement our version of Word Embedding + SVM as
the baseline method in this study. As shown in RQ1, our implementation has
quite similar results to XU's on the same data sets. Hence, we believe that our implementation reflect the original
 baseline method in \cite{xu2016predicting}. 
 
%  In RQ3, when comparing the runtime of tuning
%  SVM and CNN, we run SVM with parameter tuning experiment on a different environment
%  from XU's environment. However, we rerun our experiment on another
%  inferior experimental environment, which is a Mackbook Air computer 
%  with 1.4 GHz Intel Core i5 CPU and 8G RAM. In this experiment, we obtain
%  the similar performance scores as in RQ2 and the runtime is $16$ minutes,
%  which is till $50X$ faster than Xu et al's CNN method.
 

 
 
 Threats to \textbf{external validity} represent if the results are of relevance for
 other cases, or the ability to generalize the observations in a study. In this study,
 we compare our tuning baseline method with deep learning method, CNN, in terms of
 precision, recall, F1-score and accuracy. The experimental results are quite consistent
 for this knowledge units relatedness prediction tasks, i.e.,  multi-classification problem, in text mining. 
 Nonetheless, we do not claim that our findings can be generalized to all software analytics tasks. 
 However, those other software analytics tasks often apply deep learning
 methods~\cite{choetkiertikul2016deep, wang2016automatically} 
 and so it is quite possible that
 the methods  of this paper (DE) would
 be widely applicable, elsewhere.
 
 


\section{Conclusion}\label{conclusion}

In this paper, we perform an comparative study to investigate
how tuning can improve the baseline method compared with
the state-of-art deep learning method  for predicting
knowledge units relatedness on Stack Overflow. Our experimental
results show that:

\bi
\item Tuning improves the performance of baseline methods. 
At least for Word Embedding + SVM~(baseline in \cite{xu2016predicting}) method, if not better,
it performs as well as the proposed CNN method in \cite{xu2016predicting}.
\item The baseline method with parameter tuning runs much faster than complicated deep learning.
In this study, tuning SVM runs $84X$ faster than CNN method.
\ei


% Our findings have important implications for the software engineering community.
% Although deep learning methods have widely and successfully applied in other community
% to address problems, like pattern recognition, machine translation and recommendation
% systems, it is still unclear which type of SE task is best fit for deep learning. There are lots
% of possibilities in SE field to explore the application of deep learning. However, as pointed out
% at the beginning of this paper, deep learning is so resource-consuming technique
% and SE analytics task is usually light-weight, {the  tradeoff between performance and cost should never
% be ignored when applying deep learning}. The effort spent on deep learning might not be worthy the performance
% improved by deep learning. As shown in our experimental results, our tuning SVM gets the similar,
%  or even better, performance to deep learning while $84X$ faster.
% Therefore, it should not happen any more that simply apply deep learning on SE tasks
% without reporting and analyzing the resource consumption as well as the tradeoff.  

Based on the results of this study, we recommend that before applying 
deep learning method on SE tasks, implement
  simpler techniques which could be used,
  at the very least, for comparisons against a baseline.
   
% Also, Grid search should
% never be used as{de facto} tuning method according to \cite{fu2016differential,bergstra2012random}. 
% Xu et al failed to find the best tunings by using grid search for
% the baseline method might confirm this point.

As to the future work, we will explore more simple techniques to solve SE tasks and also
investigate how deep learning techniques could be applied effectively in software engineering
field. 




\bibliographystyle{ACM-Reference-Format}
\bibliography{0.main} 
\balance

\end{document}
